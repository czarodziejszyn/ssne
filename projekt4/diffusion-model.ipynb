{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39452209-3618-48b8-abd0-3ee695e63f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn.functional as F\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74404eca-2779-4062-b442-903da63cc0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17cec692-c09f-4461-a3eb-7e6c4276564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './trafic_32/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c90149c4-9036-48b0-b42e-fe66f054f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2a2ae8ff-4723-45d9-8977-12e2006724ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 43\n",
      "Classes: ['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007', '00008', '00009', '00010', '00011', '00012', '00013', '00014', '00015', '00016', '00017', '00018', '00019', '00020', '00021', '00022', '00023', '00024', '00025', '00026', '00027', '00028', '00029', '00030', '00031', '00032', '00033', '00034', '00035', '00036', '00037', '00038', '00039', '00040', '00041', '00042']\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "print(\"Number of classes:\", len(dataset.classes))\n",
    "print(\"Classes:\", dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8dff9692-87b0-4b21-9664-f1c3eef79f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt(x, amount):\n",
    "    if not torch.is_tensor(amount):\n",
    "        amount = torch.tensor(amount, device=x.device, dtype=x.dtype)\n",
    "    amount = amount.view(-1, 1, 1, 1)\n",
    "    noise = torch.rand_like(x)\n",
    "    return x * (1 - amount) + noise * amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bfa13285-acc7-4d6a-8e4a-0f6ff326cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a9ff1d1b-5052-47af-b7b5-191d92c115a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialNet(nn.Module):\n",
    "    def __init__(self, input_channels=3, patch_size=4, embed_dim=128, num_blocks=4):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.patch_embed = nn.Conv2d(input_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.flatten = nn.Flatten(2)\n",
    "        self.transpose = lambda x: x.transpose(1,2)\n",
    "\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(embed_dim) for _ in range(num_blocks)]\n",
    "        )\n",
    "\n",
    "        self.unflatten = lambda x: x.transpose(1, 2).reshape(x.size(0), embed_dim, 8, 8)\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.ConvTranspose2d(embed_dim, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid() # do wywalenia jeśli mse\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.view(B, C, H * W).transpose(1, 2)\n",
    "        x = self.res_blocks(x)\n",
    "        x = x.transpose(1, 2).view(B, C, H, W)\n",
    "        x = self.decode(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "acfb5470-0a18-4913-98df-8753b78bfa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000] Loss: 2.234373\n",
      "[010] Loss: 1.774741\n",
      "[020] Loss: 1.460139\n",
      "[030] Loss: 1.314956\n",
      "[040] Loss: 1.244955\n",
      "[050] Loss: 1.204571\n",
      "[060] Loss: 1.178227\n",
      "[070] Loss: 1.156814\n",
      "[080] Loss: 1.148518\n",
      "[090] Loss: 1.144521\n",
      "[100] Loss: 1.141918\n",
      "[110] Loss: 1.140125\n",
      "[120] Loss: 1.138762\n",
      "[130] Loss: 1.137631\n",
      "[140] Loss: 1.136658\n",
      "[150] Loss: 1.135828\n",
      "[160] Loss: 1.135144\n",
      "[170] Loss: 1.134579\n",
      "[180] Loss: 1.134099\n",
      "[190] Loss: 1.133683\n",
      "[199] Loss: 1.133349\n"
     ]
    }
   ],
   "source": [
    "# sanity check żeby sprawdzic czy sie uczy\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SequentialNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "x, _ = next(iter(dataloader))\n",
    "x = x[0].unsqueeze(0).to(device)\n",
    "\n",
    "def corrupt(x, noise_amount):\n",
    "    noise = noise_amount[:, None, None, None] * torch.randn_like(x)\n",
    "    return x + noise\n",
    "\n",
    "noise_amount = torch.tensor([0.5], device=device)\n",
    "noisy_x = corrupt(x, noise_amount)\n",
    "\n",
    "for step in range(200):\n",
    "    model.train()\n",
    "    pred = model(noisy_x)\n",
    "    loss = loss_fn(pred, x)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 10 == 0 or step == 199:\n",
    "        print(f\"[{step:03d}] Loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c7816653-ed56-468e-95b8-4ce342a59ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Avg Loss: 1.427083\n",
      "Epoch 2/10 | Avg Loss: 1.417355\n",
      "Epoch 3/10 | Avg Loss: 1.417129\n",
      "Epoch 4/10 | Avg Loss: 1.416930\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m     loss.backward()\n\u001b[32m     26\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     losses.append(\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     30\u001b[39m avg_loss = \u001b[38;5;28msum\u001b[39m(losses) / \u001b[38;5;28mlen\u001b[39m(losses)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Avg Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "evice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SequentialNet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "def corrupt(x, noise_amount):\n",
    "    noise = noise_amount[:, None, None, None] * torch.randn_like(x)\n",
    "    return x + noise\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for x, _ in dataloader:\n",
    "        x = x.to(device)\n",
    "\n",
    "        noise_amount = torch.rand(x.size(0), device=device)\n",
    "        noisy_x = corrupt(x, noise_amount)\n",
    "\n",
    "        pred = model(noisy_x)\n",
    "        loss = loss_fn(pred, x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Avg Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a6554491-02e1-4119-b1f3-9875681d40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "        self.down_layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "        ])\n",
    "        self.up_layers = nn.ModuleList([\n",
    "            nn.Conv2d(64 + 1, 64, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
    "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2),\n",
    "        ])\n",
    "        self.act = nn.SiLU()\n",
    "        self.downscale = nn.MaxPool2d(2)\n",
    "        self.upscale = nn.Upsample(scale_factor=2, mode='nearest', align_corners=False)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        h = []\n",
    "        for i, l in enumerate(self.down_layers):\n",
    "            x = self.act(l(x))\n",
    "            if i < 2:\n",
    "                h.append(x)\n",
    "                x = self.downscale(x)\n",
    "\n",
    "        t = t.view(-1, 1, 1, 1)\n",
    "        t = t.expand(-1, 1, x.size(2), x.size(3))\n",
    "        x = torch.cat([x, t], dim=1)\n",
    "\n",
    "        for i, l in enumerate(self.up_layers):\n",
    "            if i > 0:\n",
    "                x = F.interpolate(x, size=h[-1].shape[2:], mode='bilinear', align_corners=False)\n",
    "                x = x + h.pop()\n",
    "            x = self.act(l(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ef074f4-b7d2-47c7-be49-991fab703e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.9094\n",
      "Epoch 2/20, Loss: 0.8983\n",
      "Epoch 3/20, Loss: 0.8931\n",
      "Epoch 4/20, Loss: 0.8933\n",
      "Epoch 5/20, Loss: 0.8911\n",
      "Epoch 6/20, Loss: 0.9383\n",
      "Epoch 7/20, Loss: 0.9425\n",
      "Epoch 8/20, Loss: 0.9452\n",
      "Epoch 9/20, Loss: 0.9510\n",
      "Epoch 10/20, Loss: 0.9584\n",
      "Epoch 11/20, Loss: 0.9572\n",
      "Epoch 12/20, Loss: 0.9561\n",
      "Epoch 13/20, Loss: 0.9559\n",
      "Epoch 14/20, Loss: 0.9556\n",
      "Epoch 15/20, Loss: 0.9569\n",
      "Epoch 16/20, Loss: 1.0083\n",
      "Epoch 17/20, Loss: 1.0536\n",
      "Epoch 18/20, Loss: 1.0939\n",
      "Epoch 19/20, Loss: 1.1299\n",
      "Epoch 20/20, Loss: 1.1623\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "net = BasicUNet().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "num_epochs = 20\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    for x, _ in dataloader:\n",
    "        x = x.to(device)\n",
    "        noise_amount = torch.rand(x.size(0), device=device)\n",
    "        noisy_x = corrupt(x, noise_amount)\n",
    "        \n",
    "        pred = net(noisy_x, noise_amount)\n",
    "        loss = loss_fn(pred, x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e39f30-56df-4771-bcfa-f52f22962b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.ylim(0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900bb80-07b5-409f-ae05-442d1c300328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moj kernel",
   "language": "python",
   "name": "moj_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
